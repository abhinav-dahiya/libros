{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Writing Styles\n",
    "\n",
    "## Using Word Embeddings and Dynamic Time Warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import cPickle\n",
    "import nltk.data\n",
    "import pyprind\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set_style(\"whitegrid\")\n",
    "\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "from utils import book_data\n",
    "from fastdtw import fastdtw\n",
    "from sklearn import manifold\n",
    "from scipy.signal import gaussian\n",
    "from scipy.ndimage import filters\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import os\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding(\"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load word2vec model\n",
    "Train using `train_word2vec.py` in `src\\utils`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"data/word2vec_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=300, n_clusters=4, n_init=10,\n",
       "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs = []\n",
    "word_names = []\n",
    "for word in model.vocab:\n",
    "    vecs.append(model[word])\n",
    "    word_names.append(word)\n",
    "    \n",
    "vecs = np.array(vecs)\n",
    "km = KMeans(n_clusters=4)\n",
    "km.fit(vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Reading books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find all books for comparison\n",
    "root_path = \"../gutenberg\"\n",
    "\n",
    "all_books = []\n",
    "for f in os.listdir(root_path):\n",
    "    if f.endswith(\".epub\"):\n",
    "        all_books.append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Sentence vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "tokenizer = nltk.data.load(\"tokenizers\\punkt\\english.pickle\")\n",
    "\n",
    "bar = pyprind.ProgBar(len(all_books))\n",
    "for book in all_books:\n",
    "    data.append(book_data.get_sentence_vector(os.path.join(root_path, book), model, tokenizer))\n",
    "    bar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dtw distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dtw_distance(sig_one, sig_two, fft=False):\n",
    "    \"\"\"\n",
    "    Return dtw distance\n",
    "    \"\"\"\n",
    "    \n",
    "    if fft:\n",
    "        sig_one = np.fft.fftn(sig_one)\n",
    "        sig_two = np.fft.fftn(sig_two)\n",
    "        \n",
    "    d = fastdtw(sig_one, sig_two, dist=lambda a, b: sum((a - b) ** 2) ** 0.5)[0]\n",
    "    return np.sqrt(np.abs(d ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gauss(x, y):\n",
    "\tb = gaussian(200, 60)\n",
    "\tga = filters.convolve1d(y, b/b.sum())\n",
    "\treturn ga\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    return np.dot(a, b.T) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def clean(signal):\n",
    "    y = signal\n",
    "    x = xrange(y.shape[0])\n",
    "    y = cos_sim(y, km.cluster_centers_)\n",
    "    \n",
    "    # Filter\n",
    "    cleaned = np.zeros(y.shape)\n",
    "    for i in xrange(y.shape[1]):\n",
    "        cleaned[:, i] = gauss(x, y[:, i])\n",
    "    \n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lim = len(all_books)\n",
    "distances = -1 * np.ones((lim, lim))\n",
    "\n",
    "bar = pyprind.ProgBar(lim * lim)\n",
    "for i in xrange(lim):\n",
    "    for j in xrange(lim):\n",
    "        if i == j:\n",
    "            distances[i, j] = 0\n",
    "        else:\n",
    "            if distances[i, j] == -1:\n",
    "                dist = dtw_distance(clean(data[i]), clean(data[j]))\n",
    "                distances[i, j] = dist\n",
    "                distances[j, i] = dist\n",
    "        bar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_idx = 22 # index of book to get signal plots\n",
    "\n",
    "f, axarr = plt.subplots(4, sharex=True, figsize=(15, 13))\n",
    "\n",
    "cleaned = clean(data[plot_idx])\n",
    "\n",
    "for idx, ax in enumerate(axarr):\n",
    "    ax.plot(cos_sim(data[plot_idx], km.cluster_centers_)[:, idx], alpha=0.3)\n",
    "    ax.plot(cleaned[:, idx])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim([0, 2800])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multidimensional Scaling Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mds = manifold.MDS(\n",
    "    n_components=2,\n",
    "    max_iter=3000,\n",
    "    eps=1e-9,\n",
    "    random_state=1234,\n",
    "    dissimilarity=\"precomputed\",\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "pos = mds.fit(distances).embedding_\n",
    "\n",
    "# Rotate the data\n",
    "clf = RandomizedPCA(n_components=2)\n",
    "\n",
    "pos = clf.fit_transform(pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 15))\n",
    "\n",
    "plt.scatter(pos[:, 0], pos[:, 1], s=200)\n",
    "\n",
    "for i in xrange(len(all_books)):\n",
    "    plt.annotate(all_books[i][:-5], (pos[i, 0] + 2, pos[i, 1]))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
